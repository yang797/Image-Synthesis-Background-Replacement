{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2036971-f94f-408c-8af1-6a72d89c3837",
   "metadata": {},
   "source": [
    "## augmente for non-mask people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c106bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "def random_scale(img, base_size, scale_range=(0.5, 1.5)):\n",
    "    \"\"\"\n",
    "    随机缩放人物，保证不超出原始画布大小。\n",
    "    \"\"\"\n",
    "    base_w, base_h = base_size\n",
    "    w, h = img.size\n",
    "    # 最大缩放因子，避免缩放后宽高超出原图\n",
    "    max_scale = min(scale_range[1], base_w / w, base_h / h)\n",
    "    if max_scale < scale_range[0]:\n",
    "        return img  # 无法缩放，则跳过\n",
    "    scale = random.uniform(scale_range[0], max_scale)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    return img.resize((new_w, new_h), Image.BICUBIC)\n",
    "\n",
    "def random_rotate(img, base_size, angle_range=(-60, 60)):\n",
    "    \"\"\"\n",
    "    随机旋转人物，并保证旋转后整个人物都能放入原始画布内。\n",
    "\n",
    "    Args:\n",
    "        img (PIL.Image): 当前已做完其它变换的人物图，模式为 \"RGB\"。\n",
    "        base_size (tuple): 画布尺寸 (width, height)。\n",
    "        angle_range (tuple): 随机旋转角度范围（度数）。\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: 旋转并（如有必要）等比例缩放后的图像。\n",
    "    \"\"\"\n",
    "    base_w, base_h = base_size\n",
    "    angle = random.uniform(*angle_range)\n",
    "    # 1) 完整旋转，expand=True 能保留所有像素\n",
    "    rotated = img.rotate(\n",
    "        angle,\n",
    "        resample=Image.BICUBIC,\n",
    "        expand=True,\n",
    "        fillcolor=(0, 0, 0)\n",
    "    )\n",
    "\n",
    "    rw, rh = rotated.size\n",
    "    # 2) 如超出画布，按最小比例缩放\n",
    "    if rw > base_w or rh > base_h:\n",
    "        scale = min(base_w / rw, base_h / rh)\n",
    "        new_w, new_h = int(rw * scale), int(rh * scale)\n",
    "        rotated = rotated.resize((new_w, new_h), Image.BICUBIC)\n",
    "\n",
    "    return rotated\n",
    "\n",
    "def random_brightness(img, brightness_range=(0.5, 1.5)):\n",
    "    \"\"\"随机调整亮度。\"\"\"\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    factor = random.uniform(*brightness_range)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def random_flip(img):\n",
    "    \"\"\"50% 概率水平翻转。\"\"\"\n",
    "    if random.random() < 0.5:\n",
    "        return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return img\n",
    "\n",
    "def random_translate(img, base_size, translate_range=(-50, 50)):\n",
    "    \"\"\"\n",
    "    在黑色画布上随机平移人物，保证不超出边界。\n",
    "    \n",
    "    Arguments:\n",
    "        img (PIL.Image): 当前已变换的人物图。\n",
    "        base_size (tuple): 原始画布大小 (width, height)。\n",
    "        translate_range (tuple): 在 x 和 y 方向上允许的相对平移范围（可正可负）。\n",
    "    \"\"\"\n",
    "    base_w, base_h = base_size\n",
    "    w, h = img.size\n",
    "    # 绝对偏移区间：确保人物不会跑出画布\n",
    "    dx_min = max(-w, translate_range[0])\n",
    "    dx_max = min(base_w - w, translate_range[1])\n",
    "    dy_min = max(-h, translate_range[0])\n",
    "    dy_max = min(base_h - h, translate_range[1])\n",
    "    \n",
    "    dx = random.randint(dx_min, dx_max)\n",
    "    dy = random.randint(dy_min, dy_max)\n",
    "    \n",
    "    # # 新画布填充黑色\n",
    "    # canvas = Image.new(\"RGB\", base_size, (0, 0, 0))\n",
    "    # 贴到新位置\n",
    "    canvas.paste(img, (dx, dy))\n",
    "    return canvas\n",
    "\n",
    "def augment_image(img_path, output_dir, num_aug=5):\n",
    "    \"\"\"\n",
    "    对单张图片执行所有增强，并保存。\n",
    "    \"\"\"\n",
    "    original = Image.open(img_path)\n",
    "    base_size = original.size\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i in range(num_aug):\n",
    "        aug = original.copy()\n",
    "        \n",
    "        aug = random_scale(aug, base_size)\n",
    "        aug = random_rotate(aug, base_size)\n",
    "        aug = random_brightness(aug)\n",
    "        aug = random_flip(aug)\n",
    "        aug = random_translate(aug, base_size)\n",
    "        \n",
    "        out_path = os.path.join(output_dir, f\"{base_name}_aug_{i}.png\")\n",
    "        aug.save(out_path, format=\"PNG\")\n",
    "\n",
    "def main(input_dir, output_dir, num_aug=5):\n",
    "    \"\"\"\n",
    "    批量处理文件夹下所有 PNG 图像。\n",
    "    \"\"\"\n",
    "    files = os.listdir(input_dir)\n",
    "    for fname in files:\n",
    "        if fname.lower().endswith('.png'):\n",
    "            augment_image(\n",
    "                img_path=os.path.join(input_dir, fname),\n",
    "                output_dir=output_dir,\n",
    "                num_aug=num_aug\n",
    "            )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 请修改为你的实际路径和增强次数\n",
    "    input_directory = '../autodl-tmp/train_data_360_540_with_mask/people'\n",
    "    output_directory = '..//autodl-tmp/train_data_360_540_with_mask/people_aug'\n",
    "    augmentations_per_image = 2\n",
    "    \n",
    "    main(input_directory, output_directory, augmentations_per_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49d0e3-8524-4bf5-88c4-1e8a319b0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('autodl-tmp/train_data_360_540_augmented/people')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a44da3b-e637-47e1-8eda-d18e2182f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in os.listdir('autodl-tmp/train_data_360_540_selected/people'):\n",
    "    if name.lower().endswith('.png'):\n",
    "        pass\n",
    "    else:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d0173-7adb-4a7c-933f-7c00ae5d84ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageEnhance\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_image_and_mask(img_path):\n",
    "    \"\"\"Load image and corresponding mask (Alpha channel)\"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    if img.mode == 'RGBA':\n",
    "        # Split the image into RGB and Alpha components\n",
    "        rgb = Image.new(\"RGB\", img.size, (0, 0, 0))\n",
    "        rgb.paste(img, mask=img.split()[3])  # Use alpha as mask for proper compositing\n",
    "        return rgb, img.split()[3]  # Return (RGB, Alpha)\n",
    "    else:\n",
    "        raise ValueError(\"Input image must contain Alpha channel!\")\n",
    "\n",
    "def random_scale(img, base_size, scale_range=(0.5, 1.5)):\n",
    "    \"\"\"Random scaling with constraints\"\"\"\n",
    "    base_w, base_h = base_size\n",
    "    w, h = img.size\n",
    "    \n",
    "    max_scale = min(scale_range[1], base_w/w, base_h/h)\n",
    "    if max_scale < scale_range[0]:\n",
    "        return img\n",
    "    \n",
    "    scale = random.uniform(scale_range[0], max_scale)\n",
    "    new_size = (int(w*scale), int(h*scale))\n",
    "    return img.resize(new_size, Image.BICUBIC)\n",
    "\n",
    "def random_rotate(img, angle_range=(-60, 60)):\n",
    "    \"\"\"Rotate the image\"\"\"\n",
    "    angle = random.uniform(*angle_range)\n",
    "    fillcolor = 0 if img.mode == 'L' else (0, 0, 0)\n",
    "    return img.rotate(angle, resample=Image.BICUBIC, expand=True, fillcolor=fillcolor)\n",
    "\n",
    "def random_brightness(img, brightness_range=(0.5, 1.5)):\n",
    "    \"\"\"Adjust RGB brightness only\"\"\"\n",
    "    if img.mode == 'L':  # Skip for masks\n",
    "        return img\n",
    "    factor = random.uniform(*brightness_range)\n",
    "    return ImageEnhance.Brightness(img).enhance(factor)\n",
    "\n",
    "def random_flip(img):\n",
    "    \"\"\"Horizontal flip\"\"\"\n",
    "    if random.random() < 0.5:\n",
    "        return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return img\n",
    "\n",
    "def augment_with_mask(img_path, output_dir, num_aug=5):\n",
    "    \"\"\"Main function for synchronized mask augmentation\"\"\"\n",
    "    # Load image and extract mask\n",
    "    rgb, alpha = load_image_and_mask(img_path)\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for i in range(num_aug):\n",
    "        # Start with copies to avoid modifying originals\n",
    "        current_rgb = rgb.copy()\n",
    "        current_alpha = alpha.copy()\n",
    "        \n",
    "        # First pass: apply identical geometric transformations to both\n",
    "        \n",
    "        # 1. Scale - apply to both with same parameters\n",
    "        scale_range = (0.7, 1.3)\n",
    "        scale_factor = random.uniform(*scale_range)\n",
    "        new_size = (int(current_rgb.width * scale_factor), int(current_rgb.height * scale_factor))\n",
    "        current_rgb = current_rgb.resize(new_size, Image.BICUBIC)\n",
    "        current_alpha = current_alpha.resize(new_size, Image.BICUBIC)\n",
    "        \n",
    "        # 2. Rotation - use same angle for both\n",
    "        angle = random.uniform(-30, 30)\n",
    "        rgb_fill = (0, 0, 0)\n",
    "        alpha_fill = 0\n",
    "        current_rgb = current_rgb.rotate(angle, resample=Image.BICUBIC, expand=True, fillcolor=rgb_fill)\n",
    "        current_alpha = current_alpha.rotate(angle, resample=Image.BICUBIC, expand=True, fillcolor=alpha_fill)\n",
    "        \n",
    "        # 3. Flipping - apply same flip to both\n",
    "        if random.random() < 0.5:\n",
    "            current_rgb = current_rgb.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            current_alpha = current_alpha.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        # 4. Apply brightness only to RGB image (not to mask)\n",
    "        if random.random() < 0.7:  # 70% chance of brightness adjustment\n",
    "            brightness_factor = random.uniform(0.7, 1.3)\n",
    "            current_rgb = ImageEnhance.Brightness(current_rgb).enhance(brightness_factor)\n",
    "        \n",
    "        # 5. Translation - create same-sized canvases and paste at identical positions\n",
    "        base_size = (360, 540)  # Assuming this is your target size, adjust as needed\n",
    "        dx = random.randint(-50, 50)\n",
    "        dy = random.randint(-50, 50)\n",
    "        \n",
    "        # Create new canvases\n",
    "        rgb_canvas = Image.new(\"RGB\", base_size, (0, 0, 0))\n",
    "        alpha_canvas = Image.new(\"L\", base_size, 0)\n",
    "        \n",
    "        # Calculate paste coordinates (centered + offset)\n",
    "        paste_x = max(0, (base_size[0] - current_rgb.width) // 2 + dx)\n",
    "        paste_y = max(0, (base_size[1] - current_rgb.height) // 2 + dy)\n",
    "        \n",
    "        # Ensure we don't paste outside canvas boundaries\n",
    "        if paste_x + current_rgb.width > base_size[0]:\n",
    "            paste_x = base_size[0] - current_rgb.width\n",
    "        if paste_y + current_rgb.height > base_size[1]:\n",
    "            paste_y = base_size[1] - current_rgb.height\n",
    "        \n",
    "        # Paste at exact same position for both\n",
    "        rgb_canvas.paste(current_rgb, (paste_x, paste_y))\n",
    "        alpha_canvas.paste(current_alpha, (paste_x, paste_y))\n",
    "        \n",
    "        # Merge into RGBA\n",
    "        result = Image.merge(\"RGBA\", (*rgb_canvas.split(), alpha_canvas))\n",
    "        \n",
    "        # Save output\n",
    "        output_path = os.path.join(output_dir, f\"{base_name}_aug_{i}.png\")\n",
    "        result.save(output_path)\n",
    "        print(f\"Saved augmented image: {output_path}\")\n",
    "\n",
    "def batch_augment(input_dir, output_dir, num_aug=5):\n",
    "    \"\"\"Process all PNG images in directory\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for fname in tqdm([f for f in os.listdir(input_dir) if f.endswith('.png')]):\n",
    "        try:\n",
    "            img_path = os.path.join(input_dir, fname)\n",
    "            # print(f\"Processing: {img_path}\")\n",
    "            augment_with_mask(img_path, output_dir, num_aug)\n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f\"Error processing {fname}: {e}\")\n",
    "            pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = \"../autodl-tmp/train_data_360_540_selected/people_2_with_mask\"\n",
    "    output_dir = \"../autodl-tmp/train_data_360_540_aug_2/people\"\n",
    "    batch_augment(input_dir, output_dir, num_aug=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adffb16d-24fa-4c2a-9024-ec151492725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "def load_image_and_mask(img_path):\n",
    "    \"\"\"Load image and corresponding mask (Alpha channel)\"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    if img.mode == 'RGBA':\n",
    "        # Split the image into RGB and Alpha components\n",
    "        rgb = Image.new(\"RGB\", img.size, (0, 0, 0))\n",
    "        rgb.paste(img, mask=img.split()[3])  # Use alpha as mask for proper compositing\n",
    "        return rgb, img.split()[3]  # Return (RGB, Alpha)\n",
    "    else:\n",
    "        raise ValueError(\"Input image must contain Alpha channel!\")\n",
    "\n",
    "def get_content_bounding_box(alpha):\n",
    "    \"\"\"Get the bounding box of non-transparent content\"\"\"\n",
    "    # Convert to binary mask if needed\n",
    "    if alpha.mode != '1':\n",
    "        binary_mask = alpha.point(lambda p: 255 if p > 128 else 0)\n",
    "    else:\n",
    "        binary_mask = alpha\n",
    "    \n",
    "    # Get bounding box (left, upper, right, lower)\n",
    "    bbox = binary_mask.getbbox()\n",
    "    return bbox if bbox else (0, 0, alpha.width, alpha.height)\n",
    "\n",
    "def calculate_max_rotation(alpha, target_size):\n",
    "    \"\"\"Calculate maximum rotation angle that keeps content within bounds\"\"\"\n",
    "    # Get content bounding box\n",
    "    bbox = get_content_bounding_box(alpha)\n",
    "    content_width = bbox[2] - bbox[0]\n",
    "    content_height = bbox[3] - bbox[1]\n",
    "    \n",
    "    # Calculate diagonal length of content\n",
    "    diagonal = math.sqrt(content_width**2 + content_height**2)\n",
    "    \n",
    "    # Calculate safe margins\n",
    "    max_width = target_size[0] * 0.95  # 95% of target width\n",
    "    max_height = target_size[1] * 0.95  # 95% of target height\n",
    "    \n",
    "    # If diagonal is already too large, limit rotation\n",
    "    if diagonal > min(max_width, max_height):\n",
    "        return (-10, 10)  # Very limited rotation\n",
    "    \n",
    "    # Calculate maximum angle based on how much space is available\n",
    "    space_ratio = min(max_width / content_width, max_height / content_height)\n",
    "    \n",
    "    if space_ratio > 1.5:\n",
    "        return (-45, 45)  # Lots of space, allow large rotation\n",
    "    elif space_ratio > 1.3:\n",
    "        return (-30, 30)  # Moderate space\n",
    "    elif space_ratio > 1.1:\n",
    "        return (-15, 15)  # Limited space\n",
    "    else:\n",
    "        return (-5, 5)    # Very limited space\n",
    "\n",
    "def calculate_safe_scale_range(alpha, target_size):\n",
    "    \"\"\"Calculate safe scaling range that keeps content within bounds\"\"\"\n",
    "    # Get content bounding box\n",
    "    bbox = get_content_bounding_box(alpha)\n",
    "    content_width = bbox[2] - bbox[0]\n",
    "    content_height = bbox[3] - bbox[1]\n",
    "    \n",
    "    # Calculate maximum scale that fits in target\n",
    "    max_scale = min(\n",
    "        target_size[0] * 0.95 / content_width,\n",
    "        target_size[1] * 0.95 / content_height\n",
    "    )\n",
    "    \n",
    "    # Calculate minimum scale (don't make too small)\n",
    "    min_scale = max(0.5, min(\n",
    "        target_size[0] * 0.3 / content_width,\n",
    "        target_size[1] * 0.3 / content_height\n",
    "    ))\n",
    "    \n",
    "    # Ensure min_scale is less than max_scale\n",
    "    min_scale = min(min_scale, max_scale * 0.7)\n",
    "    \n",
    "    return (min_scale, max_scale)\n",
    "\n",
    "def augment_with_mask(img_path, output_dir, num_aug=5, target_size=(360, 540)):\n",
    "    \"\"\"Main function for synchronized mask augmentation with boundary awareness\"\"\"\n",
    "    # Load image and extract mask\n",
    "    rgb, alpha = load_image_and_mask(img_path)\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for i in range(num_aug):\n",
    "        # Start with copies to avoid modifying originals\n",
    "        current_rgb = rgb.copy()\n",
    "        current_alpha = alpha.copy()\n",
    "        \n",
    "        # Calculate safe transformation parameters\n",
    "        safe_scale_range = calculate_safe_scale_range(current_alpha, target_size)\n",
    "        safe_rotation_range = calculate_max_rotation(current_alpha, target_size)\n",
    "        \n",
    "        # 1. Scale - apply to both with same parameters within safe range\n",
    "        scale_factor = random.uniform(*safe_scale_range)\n",
    "        new_size = (int(current_rgb.width * scale_factor), int(current_rgb.height * scale_factor))\n",
    "        current_rgb = current_rgb.resize(new_size, Image.BICUBIC)\n",
    "        current_alpha = current_alpha.resize(new_size, Image.BICUBIC)\n",
    "        \n",
    "        # 2. Rotation - use same angle for both within safe range\n",
    "        angle = random.uniform(*safe_rotation_range)\n",
    "        rgb_fill = (0, 0, 0)\n",
    "        alpha_fill = 0\n",
    "        current_rgb = current_rgb.rotate(angle, resample=Image.BICUBIC, expand=True, fillcolor=rgb_fill)\n",
    "        current_alpha = current_alpha.rotate(angle, resample=Image.BICUBIC, expand=True, fillcolor=alpha_fill)\n",
    "        \n",
    "        # 3. Flipping - apply same flip to both\n",
    "        if random.random() < 0.5:\n",
    "            current_rgb = current_rgb.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            current_alpha = current_alpha.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        # 4. Apply brightness only to RGB image (not to mask)\n",
    "        if random.random() < 0.7:  # 70% chance of brightness adjustment\n",
    "            brightness_factor = random.uniform(0.7, 1.3)\n",
    "            current_rgb = ImageEnhance.Brightness(current_rgb).enhance(brightness_factor)\n",
    "        \n",
    "        # Get new content bounding box after transformations\n",
    "        content_bbox = get_content_bounding_box(current_alpha)\n",
    "        content_width = content_bbox[2] - content_bbox[0]\n",
    "        content_height = content_bbox[3] - content_bbox[1]\n",
    "        \n",
    "        # Verify content still fits within target size\n",
    "        if content_width > target_size[0] or content_height > target_size[1]:\n",
    "            # Scale down if too large\n",
    "            scale_factor = min(\n",
    "                target_size[0] / content_width,\n",
    "                target_size[1] / content_height\n",
    "            ) * 0.95  # Add a small safety margin\n",
    "            \n",
    "            new_size = (int(current_rgb.width * scale_factor), int(current_rgb.height * scale_factor))\n",
    "            current_rgb = current_rgb.resize(new_size, Image.BICUBIC)\n",
    "            current_alpha = current_alpha.resize(new_size, Image.BICUBIC)\n",
    "            \n",
    "            # Recalculate content bounding box\n",
    "            content_bbox = get_content_bounding_box(current_alpha)\n",
    "        \n",
    "        # 5. Translation - create same-sized canvases and paste at identical positions\n",
    "        # Calculate safe translation range to keep content within bounds\n",
    "        safe_x_min = max(0, target_size[0] - current_rgb.width)\n",
    "        safe_y_min = max(0, target_size[1] - current_rgb.height)\n",
    "        \n",
    "        # Generate random position within safe range\n",
    "        paste_x = random.randint(0, safe_x_min) if safe_x_min > 0 else 0\n",
    "        paste_y = random.randint(0, safe_y_min) if safe_y_min > 0 else 0\n",
    "        \n",
    "        # Create new canvases of target size\n",
    "        rgb_canvas = Image.new(\"RGB\", target_size, (0, 0, 0))\n",
    "        alpha_canvas = Image.new(\"L\", target_size, 0)\n",
    "        \n",
    "        # Paste at exact same position for both\n",
    "        rgb_canvas.paste(current_rgb, (paste_x, paste_y))\n",
    "        alpha_canvas.paste(current_alpha, (paste_x, paste_y))\n",
    "        \n",
    "        # Merge into RGBA\n",
    "        result = Image.merge(\"RGBA\", (*rgb_canvas.split(), alpha_canvas))\n",
    "        \n",
    "        # Save output\n",
    "        output_path = os.path.join(output_dir, f\"{base_name}_aug_{i}.png\")\n",
    "        result.save(output_path)\n",
    "        # print(f\"Saved augmented image: {output_path}\")\n",
    "\n",
    "def batch_augment(input_dir, output_dir, num_aug=5, target_size=(360, 540)):\n",
    "    \"\"\"Process all PNG images in directory\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for fname in [f for f in os.listdir(input_dir) if f.lower().endswith('.png')]:\n",
    "        try:\n",
    "            img_path = os.path.join(input_dir, fname)\n",
    "            # print(f\"Processing: {img_path}\")\n",
    "            augment_with_mask(img_path, output_dir, num_aug, target_size)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = \"../autodl-tmp/train_data_360_540_selected/people_2_with_mask\"\n",
    "    output_dir = \"../autodl-tmp/train_data_360_540_aug_2/people\"\n",
    "    target_size = (360, 540)  # Target canvas size\n",
    "    batch_augment(input_dir, output_dir, num_aug=4, target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7515f9eb-8391-4ca0-b938-c386b40402ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1652\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(len([f for f in os.listdir('../autodl-tmp/4_26_new_train_data_aug/masks') if f.endswith('.png')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35395a78-7a63-43af-b5b0-f9adf2177ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "def load_image_and_mask(people_path, mask_path):\n",
    "    \"\"\"Load people image and corresponding mask\"\"\"\n",
    "    try:\n",
    "        # Load people image\n",
    "        people_img = Image.open(people_path)\n",
    "        if people_img.mode != 'RGB':\n",
    "            people_img = people_img.convert('RGB')\n",
    "        \n",
    "        # Load mask image\n",
    "        mask_img = Image.open(mask_path)\n",
    "        if mask_img.mode != 'L':\n",
    "            mask_img = mask_img.convert('L')\n",
    "            \n",
    "        return people_img, mask_img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image pair: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def extract_person_from_background(people_img, mask_img):\n",
    "    \"\"\"Extract only the person from the image using the mask\"\"\"\n",
    "    # Create a transparent image (RGBA) with same dimensions\n",
    "    extracted = Image.new(\"RGBA\", people_img.size, (0, 0, 0, 0))\n",
    "    \n",
    "    # Convert RGB people image to RGBA\n",
    "    people_rgba = people_img.convert(\"RGBA\")\n",
    "    \n",
    "    # Create an RGBA version of the mask (where mask becomes alpha)\n",
    "    # This requires converting mask values (0-255) to RGBA where RGB is white and A is the mask value\n",
    "    mask_rgba = Image.new(\"RGBA\", mask_img.size)\n",
    "    \n",
    "    # For each pixel in the mask, create corresponding RGBA pixel\n",
    "    for y in range(mask_img.height):\n",
    "        for x in range(mask_img.width):\n",
    "            mask_value = mask_img.getpixel((x, y))\n",
    "            # Get the RGB value from original image\n",
    "            r, g, b = people_img.getpixel((x, y))\n",
    "            # Create RGBA with original RGB and mask as alpha\n",
    "            mask_rgba.putpixel((x, y), (r, g, b, mask_value))\n",
    "    \n",
    "    # The result is the person extracted with transparency where mask was 0\n",
    "    return mask_rgba\n",
    "\n",
    "def get_content_bounds(mask):\n",
    "    \"\"\"Get the content bounds from mask\"\"\"\n",
    "    # Convert mask to binary for bbox detection if needed\n",
    "    if mask.mode != '1':\n",
    "        binary = mask.point(lambda p: p > 0)\n",
    "    else:\n",
    "        binary = mask\n",
    "        \n",
    "    # Get bounding box (left, upper, right, lower)\n",
    "    bbox = binary.getbbox()\n",
    "    if not bbox:\n",
    "        # Return full image bounds if no content detected\n",
    "        return (0, 0, mask.width, mask.height)\n",
    "    return bbox\n",
    "\n",
    "def crop_to_content(image, mask):\n",
    "    \"\"\"Crop both image and mask to just the content area\"\"\"\n",
    "    # Get bounding box of content\n",
    "    bbox = get_content_bounds(mask)\n",
    "    \n",
    "    # Crop both image and mask to that bounding box\n",
    "    cropped_image = image.crop(bbox)\n",
    "    cropped_mask = mask.crop(bbox)\n",
    "    \n",
    "    return cropped_image, cropped_mask, bbox\n",
    "\n",
    "def calculate_safe_transformations(width, height, target_size):\n",
    "    \"\"\"Calculate safe transformation parameters to keep content in bounds\"\"\"\n",
    "    # Calculate safe margins (95% of target)\n",
    "    safe_width = target_size[0] * 0.95\n",
    "    safe_height = target_size[1] * 0.95\n",
    "    \n",
    "    # Calculate scale ranges\n",
    "    max_scale = min(\n",
    "        safe_width / width,\n",
    "        safe_height / height\n",
    "    )\n",
    "    \n",
    "    # Don't make images too small (min 30% of target)\n",
    "    min_scale = max(0.5, min(\n",
    "        target_size[0] * 0.3 / width,\n",
    "        target_size[1] * 0.3 / height\n",
    "    ))\n",
    "    \n",
    "    # Ensure min_scale doesn't exceed max_scale\n",
    "    min_scale = min(min_scale, max_scale * 0.8)\n",
    "    \n",
    "    # Calculate rotation range based on available space\n",
    "    space_ratio = min(safe_width / width, safe_height / height)\n",
    "    \n",
    "    if space_ratio > 1.5:\n",
    "        rotation_range = (-45, 45)\n",
    "    elif space_ratio > 1.3:\n",
    "        rotation_range = (-30, 30)\n",
    "    elif space_ratio > 1.1:\n",
    "        rotation_range = (-15, 15)\n",
    "    else:\n",
    "        rotation_range = (-5, 5)\n",
    "    \n",
    "    return {\n",
    "        'scale_range': (min_scale, max_scale),\n",
    "        'rotation_range': rotation_range\n",
    "    }\n",
    "\n",
    "def augment_person(people_img, mask_img, output_people_dir, output_mask_dir, base_name, index, target_size):\n",
    "    \"\"\"Augment a person image and its mask, preserving only the masked area\"\"\"\n",
    "    # Set random seed for consistent transformations\n",
    "    seed = random.randint(0, 10000)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Step 1: Extract just the person using the mask\n",
    "    extracted_person = extract_person_from_background(people_img, mask_img)\n",
    "    \n",
    "    # Step 2: Crop to content area\n",
    "    content_width = extracted_person.width\n",
    "    content_height = extracted_person.height\n",
    "    \n",
    "    # Calculate safe transformations\n",
    "    transforms = calculate_safe_transformations(content_width, content_height, target_size)\n",
    "    \n",
    "    # Step 3: Apply transformations to the extracted person\n",
    "    # 3.1 Scale\n",
    "    scale = random.uniform(*transforms['scale_range'])\n",
    "    new_width = int(extracted_person.width * scale)\n",
    "    new_height = int(extracted_person.height * scale)\n",
    "    transformed_person = extracted_person.resize((new_width, new_height), Image.BICUBIC)\n",
    "    \n",
    "    # Reset seed for consistency\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # 3.2 Rotate\n",
    "    angle = random.uniform(*transforms['rotation_range'])\n",
    "    transformed_person = transformed_person.rotate(angle, resample=Image.BICUBIC, expand=True, fillcolor=(0, 0, 0, 0))\n",
    "    \n",
    "    # Reset seed\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # 3.3 Flip (50% chance)\n",
    "    if random.random() < 0.5:\n",
    "        transformed_person = transformed_person.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    \n",
    "    # Step 4: Place on target canvas\n",
    "    # Create new RGBA canvas\n",
    "    output_canvas = Image.new(\"RGBA\", target_size, (0, 0, 0, 0))\n",
    "    \n",
    "    # Calculate centering position\n",
    "    paste_x = (target_size[0] - transformed_person.width) // 2\n",
    "    paste_y = (target_size[1] - transformed_person.height) // 2\n",
    "    \n",
    "    # Random offset from center (within safe range)\n",
    "    max_x_offset = min(paste_x, (target_size[0] - paste_x - transformed_person.width))\n",
    "    max_y_offset = min(paste_y, (target_size[1] - paste_y - transformed_person.height))\n",
    "    \n",
    "    x_offset = random.randint(-max_x_offset if max_x_offset > 0 else 0, \n",
    "                             max_x_offset if max_x_offset > 0 else 0)\n",
    "    y_offset = random.randint(-max_y_offset if max_y_offset > 0 else 0,\n",
    "                             max_y_offset if max_y_offset > 0 else 0)\n",
    "    \n",
    "    # Adjust paste position with offset\n",
    "    paste_x += x_offset\n",
    "    paste_y += y_offset\n",
    "    \n",
    "    # Ensure we don't go out of bounds\n",
    "    paste_x = max(0, min(paste_x, target_size[0] - transformed_person.width))\n",
    "    paste_y = max(0, min(paste_y, target_size[1] - transformed_person.height))\n",
    "    \n",
    "    # Paste the transformed person\n",
    "    output_canvas.paste(transformed_person, (paste_x, paste_y), transformed_person.split()[3])\n",
    "    \n",
    "    # Step 5: Separate RGB and Alpha for saving\n",
    "    rgb_output = Image.new(\"RGB\", target_size, (0, 0, 0))\n",
    "    alpha_output = Image.new(\"L\", target_size, 0)\n",
    "    \n",
    "    # Copy RGB channels from output canvas to RGB output\n",
    "    rgb_output.paste(output_canvas.convert(\"RGB\"), (0, 0))\n",
    "    \n",
    "    # Copy Alpha channel from output canvas to Alpha output\n",
    "    alpha_output.paste(output_canvas.split()[3], (0, 0))\n",
    "    \n",
    "    # Save outputs\n",
    "    people_output_path = os.path.join(output_people_dir, f\"{base_name}_aug_{index}.png\")\n",
    "    mask_output_path = os.path.join(output_mask_dir, f\"{base_name}_aug_{index}.png\")\n",
    "    # combined_output_path = os.path.join(output_people_dir, f\"{base_name}_aug_{index}_preview.png\")\n",
    "    \n",
    "    rgb_output.save(people_output_path)\n",
    "    alpha_output.save(mask_output_path)\n",
    "    # output_canvas.save(combined_output_path)  # Save combined RGBA for preview\n",
    "    \n",
    "    return people_output_path, mask_output_path\n",
    "\n",
    "def batch_augment(people_dir, mask_dir, output_people_dir, output_mask_dir, num_augmentations=5, target_size=(360, 540)):\n",
    "    \"\"\"Process all image pairs in the input directories\"\"\"\n",
    "    # Create output directories if they don't exist\n",
    "    os.makedirs(output_people_dir, exist_ok=True)\n",
    "    os.makedirs(output_mask_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all image files in people directory\n",
    "    valid_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    image_files = [f for f in os.listdir(people_dir) \n",
    "                  if os.path.isfile(os.path.join(people_dir, f)) \n",
    "                  and f.lower().endswith(valid_extensions)]\n",
    "    print(image_files)\n",
    "    processed_count = 0\n",
    "    errors_count = 0\n",
    "    \n",
    "    # Process each image pair\n",
    "    for img_file in image_files:\n",
    "        try:\n",
    "            # Check if corresponding mask exists\n",
    "            img_file = os.path.splitext(img_file)[0] + '.JPG'\n",
    "            mask_file = os.path.splitext(img_file)[0] + '.png'  # Assuming same filename in mask directory\n",
    "            if not os.path.exists(os.path.join(mask_dir, mask_file)):\n",
    "                # print(f\"Warning: No matching mask found for {img_file}\")\n",
    "                continue\n",
    "            \n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            \n",
    "            # Load the image pair\n",
    "            people_path = os.path.join(people_dir, img_file)\n",
    "            mask_path = os.path.join(mask_dir, mask_file)\n",
    "            \n",
    "            people_img, mask_img = load_image_and_mask(people_path, mask_path)\n",
    "            if people_img is None or mask_img is None:\n",
    "                print(f\"Skipping {img_file} due to loading error\")\n",
    "                errors_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Generate augmentations\n",
    "            for i in range(num_augmentations):\n",
    "                try:\n",
    "                    people_out, mask_out = augment_person(\n",
    "                        people_img, mask_img, \n",
    "                        output_people_dir, output_mask_dir,\n",
    "                        base_name, i, target_size\n",
    "                    )\n",
    "                    print(f\"Created augmentation {i+1}/{num_augmentations} for {img_file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error creating augmentation {i+1} for {img_file}: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "            \n",
    "            processed_count += 1\n",
    "            print(f\"Processed: {img_file} - created {num_augmentations} augmentations\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            errors_count += 1\n",
    "    \n",
    "    print(f\"Augmentation complete. Processed {processed_count} images with {errors_count} errors.\")\n",
    "    print(f\"Generated {processed_count * num_augmentations} augmented images.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    people_dir = \"../autodl-tmp/4_27_分类数据/道扬24/1\"  # Directory containing people images\n",
    "    mask_dir = \"../autodl-tmp/4_27_分类数据/道扬24/1_mask\"     # Directory containing mask images\n",
    "    output_people_dir = \".../autodl-tmp/4_27_aug/people\"  # Output directory for augmented people images\n",
    "    output_mask_dir = \"../autodl-tmp/4_27_aug/masks\"     # Output directory for augmented masks\n",
    "    \n",
    "    num_augmentations = 4\n",
    "    target_size = (360, 360)  # Fixed size for all outputs\n",
    "    \n",
    "    # Run the augmentation\n",
    "    batch_augment(people_dir, mask_dir, output_people_dir, output_mask_dir, num_augmentations, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc67d25a-966c-4240-89e4-19d07bb6be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KIT_9007.JPG', 'KIT_9034.JPG', 'KIT_9048.JPG', 'KIT_9051.JPG', 'KIT_9087.JPG', 'KIT_9060.JPG', 'KIT_9105.JPG', 'KIT_9098.JPG', 'KIT_9113.JPG', 'KIT_9128.JPG', 'KIT_9116.JPG', 'KIT_9141.JPG', 'KIT_9136.JPG', 'KIT_9147.JPG', 'KIT_9166.JPG', 'KIT_9178.JPG', 'KIT_9168.JPG', '_DSC4492.JPG', '_DSC4513.JPG', '_DSC4548.JPG', '_DSC4552.JPG', '_DSC4555.JPG', '_DSC4560.JPG', '_DSC4565.JPG', '_DSC4585.JPG', '_DSC4593.JPG', '_DSC4612.JPG', '_DSC4601.JPG', '_DSC4627.JPG', '_DSC4616.JPG', '_DSC4643.JPG', '_DSC4669.JPG', '_DSC4640.JPG', '_DSC4678.JPG', '_DSC4674.JPG', '_DSC4679.JPG', '_DSC4681.JPG']\n",
      "Created augmentation 1/4 for KIT_9007.JPG\n",
      "Created augmentation 2/4 for KIT_9007.JPG\n",
      "Created augmentation 3/4 for KIT_9007.JPG\n",
      "Created augmentation 4/4 for KIT_9007.JPG\n",
      "Processed: KIT_9007.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9034.JPG\n",
      "Created augmentation 2/4 for KIT_9034.JPG\n",
      "Created augmentation 3/4 for KIT_9034.JPG\n",
      "Created augmentation 4/4 for KIT_9034.JPG\n",
      "Processed: KIT_9034.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9048.JPG\n",
      "Created augmentation 2/4 for KIT_9048.JPG\n",
      "Created augmentation 3/4 for KIT_9048.JPG\n",
      "Created augmentation 4/4 for KIT_9048.JPG\n",
      "Processed: KIT_9048.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9051.JPG\n",
      "Created augmentation 2/4 for KIT_9051.JPG\n",
      "Created augmentation 3/4 for KIT_9051.JPG\n",
      "Created augmentation 4/4 for KIT_9051.JPG\n",
      "Processed: KIT_9051.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9087.JPG\n",
      "Created augmentation 2/4 for KIT_9087.JPG\n",
      "Created augmentation 3/4 for KIT_9087.JPG\n",
      "Created augmentation 4/4 for KIT_9087.JPG\n",
      "Processed: KIT_9087.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9060.JPG\n",
      "Created augmentation 2/4 for KIT_9060.JPG\n",
      "Created augmentation 3/4 for KIT_9060.JPG\n",
      "Created augmentation 4/4 for KIT_9060.JPG\n",
      "Processed: KIT_9060.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9105.JPG\n",
      "Created augmentation 2/4 for KIT_9105.JPG\n",
      "Created augmentation 3/4 for KIT_9105.JPG\n",
      "Created augmentation 4/4 for KIT_9105.JPG\n",
      "Processed: KIT_9105.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9098.JPG\n",
      "Created augmentation 2/4 for KIT_9098.JPG\n",
      "Created augmentation 3/4 for KIT_9098.JPG\n",
      "Created augmentation 4/4 for KIT_9098.JPG\n",
      "Processed: KIT_9098.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9113.JPG\n",
      "Created augmentation 2/4 for KIT_9113.JPG\n",
      "Created augmentation 3/4 for KIT_9113.JPG\n",
      "Created augmentation 4/4 for KIT_9113.JPG\n",
      "Processed: KIT_9113.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9128.JPG\n",
      "Created augmentation 2/4 for KIT_9128.JPG\n",
      "Created augmentation 3/4 for KIT_9128.JPG\n",
      "Created augmentation 4/4 for KIT_9128.JPG\n",
      "Processed: KIT_9128.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9116.JPG\n",
      "Created augmentation 2/4 for KIT_9116.JPG\n",
      "Created augmentation 3/4 for KIT_9116.JPG\n",
      "Created augmentation 4/4 for KIT_9116.JPG\n",
      "Processed: KIT_9116.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9141.JPG\n",
      "Created augmentation 2/4 for KIT_9141.JPG\n",
      "Created augmentation 3/4 for KIT_9141.JPG\n",
      "Created augmentation 4/4 for KIT_9141.JPG\n",
      "Processed: KIT_9141.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9136.JPG\n",
      "Created augmentation 2/4 for KIT_9136.JPG\n",
      "Created augmentation 3/4 for KIT_9136.JPG\n",
      "Created augmentation 4/4 for KIT_9136.JPG\n",
      "Processed: KIT_9136.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9147.JPG\n",
      "Created augmentation 2/4 for KIT_9147.JPG\n",
      "Created augmentation 3/4 for KIT_9147.JPG\n",
      "Created augmentation 4/4 for KIT_9147.JPG\n",
      "Processed: KIT_9147.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9166.JPG\n",
      "Created augmentation 2/4 for KIT_9166.JPG\n",
      "Created augmentation 3/4 for KIT_9166.JPG\n",
      "Created augmentation 4/4 for KIT_9166.JPG\n",
      "Processed: KIT_9166.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9178.JPG\n",
      "Created augmentation 2/4 for KIT_9178.JPG\n",
      "Created augmentation 3/4 for KIT_9178.JPG\n",
      "Created augmentation 4/4 for KIT_9178.JPG\n",
      "Processed: KIT_9178.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for KIT_9168.JPG\n",
      "Created augmentation 2/4 for KIT_9168.JPG\n",
      "Created augmentation 3/4 for KIT_9168.JPG\n",
      "Created augmentation 4/4 for KIT_9168.JPG\n",
      "Processed: KIT_9168.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4492.JPG\n",
      "Created augmentation 2/4 for _DSC4492.JPG\n",
      "Created augmentation 3/4 for _DSC4492.JPG\n",
      "Created augmentation 4/4 for _DSC4492.JPG\n",
      "Processed: _DSC4492.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4513.JPG\n",
      "Created augmentation 2/4 for _DSC4513.JPG\n",
      "Created augmentation 3/4 for _DSC4513.JPG\n",
      "Created augmentation 4/4 for _DSC4513.JPG\n",
      "Processed: _DSC4513.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4548.JPG\n",
      "Created augmentation 2/4 for _DSC4548.JPG\n",
      "Created augmentation 3/4 for _DSC4548.JPG\n",
      "Created augmentation 4/4 for _DSC4548.JPG\n",
      "Processed: _DSC4548.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4552.JPG\n",
      "Created augmentation 2/4 for _DSC4552.JPG\n",
      "Created augmentation 3/4 for _DSC4552.JPG\n",
      "Created augmentation 4/4 for _DSC4552.JPG\n",
      "Processed: _DSC4552.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4555.JPG\n",
      "Created augmentation 2/4 for _DSC4555.JPG\n",
      "Created augmentation 3/4 for _DSC4555.JPG\n",
      "Created augmentation 4/4 for _DSC4555.JPG\n",
      "Processed: _DSC4555.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4560.JPG\n",
      "Created augmentation 2/4 for _DSC4560.JPG\n",
      "Created augmentation 3/4 for _DSC4560.JPG\n",
      "Created augmentation 4/4 for _DSC4560.JPG\n",
      "Processed: _DSC4560.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4565.JPG\n",
      "Created augmentation 2/4 for _DSC4565.JPG\n",
      "Created augmentation 3/4 for _DSC4565.JPG\n",
      "Created augmentation 4/4 for _DSC4565.JPG\n",
      "Processed: _DSC4565.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4585.JPG\n",
      "Created augmentation 2/4 for _DSC4585.JPG\n",
      "Created augmentation 3/4 for _DSC4585.JPG\n",
      "Created augmentation 4/4 for _DSC4585.JPG\n",
      "Processed: _DSC4585.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4593.JPG\n",
      "Created augmentation 2/4 for _DSC4593.JPG\n",
      "Created augmentation 3/4 for _DSC4593.JPG\n",
      "Created augmentation 4/4 for _DSC4593.JPG\n",
      "Processed: _DSC4593.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4612.JPG\n",
      "Created augmentation 2/4 for _DSC4612.JPG\n",
      "Created augmentation 3/4 for _DSC4612.JPG\n",
      "Created augmentation 4/4 for _DSC4612.JPG\n",
      "Processed: _DSC4612.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4601.JPG\n",
      "Created augmentation 2/4 for _DSC4601.JPG\n",
      "Created augmentation 3/4 for _DSC4601.JPG\n",
      "Created augmentation 4/4 for _DSC4601.JPG\n",
      "Processed: _DSC4601.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4627.JPG\n",
      "Created augmentation 2/4 for _DSC4627.JPG\n",
      "Created augmentation 3/4 for _DSC4627.JPG\n",
      "Created augmentation 4/4 for _DSC4627.JPG\n",
      "Processed: _DSC4627.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4616.JPG\n",
      "Created augmentation 2/4 for _DSC4616.JPG\n",
      "Created augmentation 3/4 for _DSC4616.JPG\n",
      "Created augmentation 4/4 for _DSC4616.JPG\n",
      "Processed: _DSC4616.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4643.JPG\n",
      "Created augmentation 2/4 for _DSC4643.JPG\n",
      "Created augmentation 3/4 for _DSC4643.JPG\n",
      "Created augmentation 4/4 for _DSC4643.JPG\n",
      "Processed: _DSC4643.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4669.JPG\n",
      "Created augmentation 2/4 for _DSC4669.JPG\n",
      "Created augmentation 3/4 for _DSC4669.JPG\n",
      "Created augmentation 4/4 for _DSC4669.JPG\n",
      "Processed: _DSC4669.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4640.JPG\n",
      "Created augmentation 2/4 for _DSC4640.JPG\n",
      "Created augmentation 3/4 for _DSC4640.JPG\n",
      "Created augmentation 4/4 for _DSC4640.JPG\n",
      "Processed: _DSC4640.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4678.JPG\n",
      "Created augmentation 2/4 for _DSC4678.JPG\n",
      "Created augmentation 3/4 for _DSC4678.JPG\n",
      "Created augmentation 4/4 for _DSC4678.JPG\n",
      "Processed: _DSC4678.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4674.JPG\n",
      "Created augmentation 2/4 for _DSC4674.JPG\n",
      "Created augmentation 3/4 for _DSC4674.JPG\n",
      "Created augmentation 4/4 for _DSC4674.JPG\n",
      "Processed: _DSC4674.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4679.JPG\n",
      "Created augmentation 2/4 for _DSC4679.JPG\n",
      "Created augmentation 3/4 for _DSC4679.JPG\n",
      "Created augmentation 4/4 for _DSC4679.JPG\n",
      "Processed: _DSC4679.JPG - created 4 augmentations\n",
      "Created augmentation 1/4 for _DSC4681.JPG\n",
      "Created augmentation 2/4 for _DSC4681.JPG\n",
      "Created augmentation 3/4 for _DSC4681.JPG\n",
      "Created augmentation 4/4 for _DSC4681.JPG\n",
      "Processed: _DSC4681.JPG - created 4 augmentations\n",
      "Augmentation complete. Processed 37 images with 0 errors.\n",
      "Generated 148 augmented images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "def load_image_and_mask(people_path, mask_path):\n",
    "    \"\"\"Load people image and corresponding mask\"\"\"\n",
    "    try:\n",
    "        # Load people image\n",
    "        people_img = Image.open(people_path)\n",
    "        if people_img.mode != 'RGB':\n",
    "            people_img = people_img.convert('RGB')\n",
    "        \n",
    "        # Load mask image\n",
    "        mask_img = Image.open(mask_path)\n",
    "        if mask_img.mode != 'L':\n",
    "            mask_img = mask_img.convert('L')\n",
    "            \n",
    "        return people_img, mask_img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image pair: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def extract_person_from_background(people_img, mask_img):\n",
    "    \"\"\"Extract only the person from the image using the mask\"\"\"\n",
    "    # Create a transparent image (RGBA) with same dimensions\n",
    "    extracted = Image.new(\"RGBA\", people_img.size, (0, 0, 0, 0))\n",
    "    \n",
    "    # Convert RGB people image to RGBA\n",
    "    people_rgba = people_img.convert(\"RGBA\")\n",
    "    \n",
    "    # Create an RGBA version of the mask (where mask becomes alpha)\n",
    "    # This requires converting mask values (0-255) to RGBA where RGB is white and A is the mask value\n",
    "    mask_rgba = Image.new(\"RGBA\", mask_img.size)\n",
    "    \n",
    "    # For each pixel in the mask, create corresponding RGBA pixel\n",
    "    for y in range(mask_img.height):\n",
    "        for x in range(mask_img.width):\n",
    "            mask_value = mask_img.getpixel((x, y))\n",
    "            # Get the RGB value from original image\n",
    "            r, g, b = people_img.getpixel((x, y))\n",
    "            # Create RGBA with original RGB and mask as alpha\n",
    "            mask_rgba.putpixel((x, y), (r, g, b, mask_value))\n",
    "    \n",
    "    # The result is the person extracted with transparency where mask was 0\n",
    "    return mask_rgba\n",
    "\n",
    "def get_content_bounds(mask):\n",
    "    \"\"\"Get the content bounds from mask\"\"\"\n",
    "    # Convert mask to binary for bbox detection if needed\n",
    "    if mask.mode != '1':\n",
    "        binary = mask.point(lambda p: p > 0)\n",
    "    else:\n",
    "        binary = mask\n",
    "        \n",
    "    # Get bounding box (left, upper, right, lower)\n",
    "    bbox = binary.getbbox()\n",
    "    if not bbox:\n",
    "        # Return full image bounds if no content detected\n",
    "        return (0, 0, mask.width, mask.height)\n",
    "    return bbox\n",
    "\n",
    "def crop_to_content(image, mask):\n",
    "    \"\"\"Crop both image and mask to just the content area\"\"\"\n",
    "    # Get bounding box of content\n",
    "    bbox = get_content_bounds(mask)\n",
    "    \n",
    "    # Crop both image and mask to that bounding box\n",
    "    cropped_image = image.crop(bbox)\n",
    "    cropped_mask = mask.crop(bbox)\n",
    "    \n",
    "    return cropped_image, cropped_mask, bbox\n",
    "\n",
    "def calculate_safe_transformations(width, height, target_size):\n",
    "    \"\"\"Calculate safe transformation parameters to keep content in bounds\"\"\"\n",
    "    # Calculate safe margins (95% of target)\n",
    "    safe_width = target_size[0] * 0.95\n",
    "    safe_height = target_size[1] * 0.95\n",
    "    \n",
    "    # Calculate scale ranges\n",
    "    max_scale = min(\n",
    "        safe_width / width,\n",
    "        safe_height / height\n",
    "    )\n",
    "    \n",
    "    # Don't make images too small (min 30% of target)\n",
    "    min_scale = max(0.5, min(\n",
    "        target_size[0] * 0.3 / width,\n",
    "        target_size[1] * 0.3 / height\n",
    "    ))\n",
    "    \n",
    "    # Ensure min_scale doesn't exceed max_scale\n",
    "    min_scale = min(min_scale, max_scale * 0.8)\n",
    "    \n",
    "    # Calculate rotation range based on available space\n",
    "    space_ratio = min(safe_width / width, safe_height / height)\n",
    "    \n",
    "    if space_ratio > 1.5:\n",
    "        rotation_range = (-45, 45)\n",
    "    elif space_ratio > 1.3:\n",
    "        rotation_range = (-30, 30)\n",
    "    elif space_ratio > 1.1:\n",
    "        rotation_range = (-15, 15)\n",
    "    else:\n",
    "        rotation_range = (-5, 5)\n",
    "    \n",
    "    return {\n",
    "        'scale_range': (min_scale, max_scale),\n",
    "        'rotation_range': rotation_range\n",
    "    }\n",
    "\n",
    "def augment_person(people_img, mask_img, output_people_dir, output_mask_dir, base_name, index):\n",
    "    \"\"\"Augment a person image and its mask, preserving original size\"\"\"\n",
    "    # Set random seed for consistent transformations\n",
    "    seed = random.randint(0, 10000)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Step 1: Extract just the person using the mask\n",
    "    extracted_person = extract_person_from_background(people_img, mask_img)\n",
    "    \n",
    "    # Step 2: Crop to content area (optional, keeps only the person)\n",
    "    cropped_person, cropped_mask, bbox = crop_to_content(extracted_person, mask_img)\n",
    "    \n",
    "    # Step 3: Apply transformations to the extracted person\n",
    "    # 3.1 Scale (randomly resize within a reasonable range)\n",
    "    scale = random.uniform(0.8, 1.2)  # Example: 80% to 120% of original size\n",
    "    new_width = int(cropped_person.width * scale)\n",
    "    new_height = int(cropped_person.height * scale)\n",
    "    transformed_person = cropped_person.resize((new_width, new_height), Image.BICUBIC)\n",
    "    \n",
    "    # Reset seed for consistency\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # 3.2 Rotate (smaller range to avoid excessive empty space)\n",
    "    angle = random.uniform(-15, 15)  # Reduced rotation range\n",
    "    transformed_person = transformed_person.rotate(angle, resample=Image.BICUBIC, expand=True, fillcolor=(0, 0, 0, 0))\n",
    "    \n",
    "    # Reset seed\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # 3.3 Flip (50% chance)\n",
    "    if random.random() < 0.5:\n",
    "        transformed_person = transformed_person.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    \n",
    "    # Step 4: Place on canvas with ORIGINAL DIMENSIONS\n",
    "    original_width, original_height = people_img.size\n",
    "    output_canvas = Image.new(\"RGBA\", (original_width, original_height), (0, 0, 0, 0))\n",
    "    \n",
    "    # Center the transformed person\n",
    "    paste_x = (original_width - transformed_person.width) // 2\n",
    "    paste_y = (original_height - transformed_person.height) // 2\n",
    "    \n",
    "    # Paste the transformed person\n",
    "    output_canvas.paste(transformed_person, (paste_x, paste_y), transformed_person.split()[3])\n",
    "    \n",
    "    # Step 5: Separate RGB and Alpha for saving\n",
    "    rgb_output = output_canvas.convert(\"RGB\")\n",
    "    alpha_output = output_canvas.split()[3]  # Alpha channel\n",
    "    \n",
    "    # Save outputs\n",
    "    people_output_path = os.path.join(output_people_dir, f\"{base_name}_aug_{index}.png\")\n",
    "    mask_output_path = os.path.join(output_mask_dir, f\"{base_name}_aug_{index}.png\")\n",
    "    \n",
    "    rgb_output.save(people_output_path)\n",
    "    alpha_output.save(mask_output_path)\n",
    "    \n",
    "    return people_output_path, mask_output_path\n",
    "\n",
    "\n",
    "def batch_augment(people_dir, mask_dir, output_people_dir, output_mask_dir, num_augmentations=5):\n",
    "    \"\"\"Process all image pairs in the input directories\"\"\"\n",
    "    # Create output directories if they don't exist\n",
    "    os.makedirs(output_people_dir, exist_ok=True)\n",
    "    os.makedirs(output_mask_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all image files in people directory\n",
    "    valid_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    image_files = [f for f in os.listdir(people_dir) \n",
    "                  if os.path.isfile(os.path.join(people_dir, f)) \n",
    "                  and f.lower().endswith(valid_extensions)]\n",
    "    print(image_files)\n",
    "    processed_count = 0\n",
    "    errors_count = 0\n",
    "    \n",
    "    # Process each image pair\n",
    "    for img_file in image_files:\n",
    "        try:\n",
    "            # Check if corresponding mask exists\n",
    "            img_file = os.path.splitext(img_file)[0] + '.JPG'\n",
    "            mask_file = os.path.splitext(img_file)[0] + '.png'  # Assuming same filename in mask directory\n",
    "            if not os.path.exists(os.path.join(mask_dir, mask_file)):\n",
    "                # print(f\"Warning: No matching mask found for {img_file}\")\n",
    "                continue\n",
    "            \n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            \n",
    "            # Load the image pair\n",
    "            people_path = os.path.join(people_dir, img_file)\n",
    "            mask_path = os.path.join(mask_dir, mask_file)\n",
    "            \n",
    "            people_img, mask_img = load_image_and_mask(people_path, mask_path)\n",
    "            if people_img is None or mask_img is None:\n",
    "                print(f\"Skipping {img_file} due to loading error\")\n",
    "                errors_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Generate augmentations\n",
    "            for i in range(num_augmentations):\n",
    "                try:\n",
    "                    people_out, mask_out = augment_person(\n",
    "                        people_img, mask_img, \n",
    "                        output_people_dir, output_mask_dir,\n",
    "                        base_name, i  # No target_size passed\n",
    "                    )\n",
    "\n",
    "                    print(f\"Created augmentation {i+1}/{num_augmentations} for {img_file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error creating augmentation {i+1} for {img_file}: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "            \n",
    "            processed_count += 1\n",
    "            print(f\"Processed: {img_file} - created {num_augmentations} augmentations\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            errors_count += 1\n",
    "    \n",
    "    print(f\"Augmentation complete. Processed {processed_count} images with {errors_count} errors.\")\n",
    "    print(f\"Generated {processed_count * num_augmentations} augmented images.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    people_dir = \"../autodl-tmp/4_27_分类数据/道扬24/2\"  # Directory containing people images\n",
    "    mask_dir = \"../autodl-tmp/4_27_分类数据/道扬24/2_mask\"     # Directory containing mask images\n",
    "    output_people_dir = \"../autodl-tmp/4_27_aug/people\"  # Output directory for augmented people images\n",
    "    output_mask_dir = \"../autodl-tmp/4_27_aug/masks\"     # Output directory for augmented masks\n",
    "    \n",
    "    num_augmentations = 4\n",
    "    # target_size = (360, 360)  # Fixed size for all outputs\n",
    "    \n",
    "    # Run the augmentation\n",
    "    batch_augment(people_dir, mask_dir, output_people_dir, output_mask_dir, num_augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4b73c-4681-4ace-9a2e-fe74256237a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
